{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbobbypestana\u001b[0m (\u001b[33mbobbypestana-kvantify\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/g/My Drive/projetos_individuais/GAN/wandb/run-20240911_142654-w6xij33g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bobbypestana-kvantify/gan-noise-investigation-2/runs/w6xij33g' target=\"_blank\">comic-serenity-6</a></strong> to <a href='https://wandb.ai/bobbypestana-kvantify/gan-noise-investigation-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bobbypestana-kvantify/gan-noise-investigation-2' target=\"_blank\">https://wandb.ai/bobbypestana-kvantify/gan-noise-investigation-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bobbypestana-kvantify/gan-noise-investigation-2/runs/w6xij33g' target=\"_blank\">https://wandb.ai/bobbypestana-kvantify/gan-noise-investigation-2/runs/w6xij33g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/200], Step [300/1200], D Loss: 0.3354, G Loss: 2.3762, D(x): 0.94, D(G(z)): 0.23, Time Elapsed: 5.01 sec\n",
      "Epoch [0/200], Step [600/1200], D Loss: 0.1203, G Loss: 5.3818, D(x): 0.96, D(G(z)): 0.06, Time Elapsed: 8.62 sec\n",
      "Epoch [0/200], Step [900/1200], D Loss: 0.1545, G Loss: 3.5579, D(x): 0.98, D(G(z)): 0.12, Time Elapsed: 12.00 sec\n",
      "Epoch [0/200], Step [1200/1200], D Loss: 0.0454, G Loss: 3.9309, D(x): 0.99, D(G(z)): 0.04, Time Elapsed: 15.66 sec\n",
      "Epoch [1/200], Step [300/1200], D Loss: 0.0210, G Loss: 5.1269, D(x): 0.99, D(G(z)): 0.01, Time Elapsed: 3.73 sec\n",
      "Epoch [1/200], Step [600/1200], D Loss: 0.0813, G Loss: 6.6114, D(x): 0.95, D(G(z)): 0.03, Time Elapsed: 7.14 sec\n",
      "Epoch [1/200], Step [900/1200], D Loss: 0.0868, G Loss: 6.7348, D(x): 0.95, D(G(z)): 0.02, Time Elapsed: 10.51 sec\n",
      "Epoch [1/200], Step [1200/1200], D Loss: 0.0284, G Loss: 4.9750, D(x): 0.99, D(G(z)): 0.02, Time Elapsed: 13.68 sec\n",
      "Epoch [2/200], Step [300/1200], D Loss: 0.4066, G Loss: 6.9971, D(x): 0.82, D(G(z)): 0.07, Time Elapsed: 3.31 sec\n",
      "Epoch [2/200], Step [600/1200], D Loss: 0.6515, G Loss: 6.3737, D(x): 0.87, D(G(z)): 0.32, Time Elapsed: 6.67 sec\n",
      "Epoch [2/200], Step [900/1200], D Loss: 0.0666, G Loss: 4.8506, D(x): 0.96, D(G(z)): 0.02, Time Elapsed: 9.96 sec\n",
      "Epoch [2/200], Step [1200/1200], D Loss: 0.0013, G Loss: 7.6618, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 13.30 sec\n",
      "Epoch [3/200], Step [300/1200], D Loss: 0.0344, G Loss: 5.5547, D(x): 0.99, D(G(z)): 0.02, Time Elapsed: 3.35 sec\n",
      "Epoch [3/200], Step [600/1200], D Loss: 0.0136, G Loss: 6.0412, D(x): 1.00, D(G(z)): 0.01, Time Elapsed: 6.87 sec\n",
      "Epoch [3/200], Step [900/1200], D Loss: 0.1011, G Loss: 5.7337, D(x): 0.97, D(G(z)): 0.06, Time Elapsed: 10.27 sec\n",
      "Epoch [3/200], Step [1200/1200], D Loss: 0.0420, G Loss: 4.9582, D(x): 1.00, D(G(z)): 0.04, Time Elapsed: 13.83 sec\n",
      "Epoch [4/200], Step [300/1200], D Loss: 0.0018, G Loss: 6.5093, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 3.39 sec\n",
      "Epoch [4/200], Step [600/1200], D Loss: 0.0007, G Loss: 7.6359, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 6.57 sec\n",
      "Epoch [4/200], Step [900/1200], D Loss: 0.0182, G Loss: 4.8705, D(x): 1.00, D(G(z)): 0.02, Time Elapsed: 9.59 sec\n",
      "Epoch [4/200], Step [1200/1200], D Loss: 0.0003, G Loss: 8.6874, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 12.61 sec\n",
      "Epoch [5/200], Step [300/1200], D Loss: 0.0034, G Loss: 6.1357, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 3.10 sec\n",
      "Epoch [5/200], Step [600/1200], D Loss: 0.0019, G Loss: 6.4313, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 6.52 sec\n",
      "Epoch [5/200], Step [900/1200], D Loss: 0.0005, G Loss: 9.8039, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 10.11 sec\n",
      "Epoch [5/200], Step [1200/1200], D Loss: 0.0060, G Loss: 6.6692, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 13.72 sec\n",
      "Epoch [6/200], Step [300/1200], D Loss: 0.0009, G Loss: 7.0802, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 3.53 sec\n",
      "Epoch [6/200], Step [600/1200], D Loss: 0.0027, G Loss: 6.7737, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 6.97 sec\n",
      "Epoch [6/200], Step [900/1200], D Loss: 0.0000, G Loss: 10.8577, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 10.44 sec\n",
      "Epoch [6/200], Step [1200/1200], D Loss: 0.0000, G Loss: 12.2249, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 13.78 sec\n",
      "Epoch [7/200], Step [300/1200], D Loss: 0.0000, G Loss: 12.3178, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 3.25 sec\n",
      "Epoch [7/200], Step [600/1200], D Loss: 0.0000, G Loss: 12.5617, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 6.57 sec\n",
      "Epoch [7/200], Step [900/1200], D Loss: 0.0000, G Loss: 12.6873, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 10.15 sec\n",
      "Epoch [7/200], Step [1200/1200], D Loss: 0.0000, G Loss: 13.6021, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 13.87 sec\n",
      "Epoch [8/200], Step [300/1200], D Loss: 0.0000, G Loss: 13.7404, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 3.57 sec\n",
      "Epoch [8/200], Step [600/1200], D Loss: 0.0000, G Loss: 13.6655, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 7.12 sec\n",
      "Epoch [8/200], Step [900/1200], D Loss: 0.0000, G Loss: 12.9454, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 10.94 sec\n",
      "Epoch [8/200], Step [1200/1200], D Loss: 0.0000, G Loss: 13.1773, D(x): 1.00, D(G(z)): 0.00, Time Elapsed: 14.59 sec\n",
      "Stopping training as D(x) ≈ 1.00 and D(G(z)) ≈ 0.00 for 5 consecutive epochs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f4bddcf3c2432abbef550784ecc814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>D Loss</td><td>▅▂▃▁▁▂▂▁▅█▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>D(G(z))</td><td>▆▂▄▂▁▂▂▁▂█▁▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>D(x)</td><td>▆▆▇█▇▆▆█▁▃▆███▇█████████████████████</td></tr><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>G Loss</td><td>▁▃▂▂▃▄▄▃▄▃▃▄▃▃▃▃▄▄▃▅▃▃▆▄▄▄▆▇▇▇▇█████</td></tr><tr><td>Monobit Frequency Test</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Noise Entropy</td><td>▆▅█▃▅▆▅▇▆▅▅▅▅▁▆▆▅▅▃▇▅▆▆▅▄▅█▆▅▅▅▅▅▇▅▄</td></tr><tr><td>Noise Kurtosis</td><td>▂▃▂▃▃▂▃▁▂▃▃▃▃█▃▂▂▃▄▂▃▃▂▂▃▂▁▃▄▂▂▂▃▂▂▄</td></tr><tr><td>Noise Mean</td><td>█▃▄▆▄▅▁▆█▄▁▅▇█▆▃▄▇▄▂▄▅▅▄▄▅▆▂▄▆▆▄▃▃▃▅</td></tr><tr><td>Noise Range</td><td>▂▃▁▄▃▂▂▁▂▃▃▃▃█▂▂▃▃▄▁▂▂▂▃▃▃▁▂▃▃▃▂▃▂▃▄</td></tr><tr><td>Noise Skewness</td><td>▃▄▂▃▅▃▄▂▃▄▄▅▅█▄▃▂▄▅▄▄▄▃▃▅▃▁▄▆▃▃▃▄▂▄▅</td></tr><tr><td>Noise Std</td><td>▅▂▃▂▄▃▁▅▅▄▂▄█▇▄▂▃▅▃▃▃▅▅▃▆▃▃▄▅▅▆▃▄▂▅▆</td></tr><tr><td>Runs Test</td><td>█▅▃▆▆▅▂▃█▄▁▇▄▇▅▄▃▆▆▄▆▄▆▁▅▆▅▂▄▅▃▆▁▄▂▃</td></tr><tr><td>Time Elapsed</td><td>▂▄▆█▁▃▅▇▁▃▅▇▁▃▅▇▁▃▅▆▁▃▅▇▁▃▅▇▁▃▅▇▁▃▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Block Frequency Test</td><td>nan</td></tr><tr><td>D Loss</td><td>0.0</td></tr><tr><td>D(G(z))</td><td>0.0</td></tr><tr><td>D(x)</td><td>1.0</td></tr><tr><td>Epoch</td><td>8</td></tr><tr><td>G Loss</td><td>13.1773</td></tr><tr><td>Longest Runs of Ones Test</td><td>nan</td></tr><tr><td>Monobit Frequency Test</td><td>1.0</td></tr><tr><td>Noise Entropy</td><td>12.61408</td></tr><tr><td>Noise Kurtosis</td><td>3.63846</td></tr><tr><td>Noise Mean</td><td>2.00689</td></tr><tr><td>Noise Range</td><td>12.47073</td></tr><tr><td>Noise Skewness</td><td>1.51442</td></tr><tr><td>Noise Std</td><td>1.44331</td></tr><tr><td>Runs Test</td><td>0.0</td></tr><tr><td>Time Elapsed</td><td>14.58567</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comic-serenity-6</strong> at: <a href='https://wandb.ai/bobbypestana-kvantify/gan-noise-investigation-2/runs/w6xij33g' target=\"_blank\">https://wandb.ai/bobbypestana-kvantify/gan-noise-investigation-2/runs/w6xij33g</a><br/> View project at: <a href='https://wandb.ai/bobbypestana-kvantify/gan-noise-investigation-2' target=\"_blank\">https://wandb.ai/bobbypestana-kvantify/gan-noise-investigation-2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240911_142654-w6xij33g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import wandb\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Initialize Weights & Biases\n",
    "wandb.init(project=\"gan-noise-investigation-2\")\n",
    "\n",
    "# Configuration for W&B\n",
    "config = wandb.config\n",
    "config.latent_size = 64\n",
    "config.hidden_size = 256\n",
    "config.image_size = 784\n",
    "config.batch_size = 50\n",
    "config.learning_rate = 0.0002\n",
    "config.num_epochs = 200\n",
    "config.noise_mean = 0.0   # Mean for normal and lognormal distribution\n",
    "config.noise_std = 1.0    # Standard deviation for normal and lognormal\n",
    "config.noise_min = -1.0   # Min for uniform distribution\n",
    "config.noise_max = 1.0    # Max for uniform distribution\n",
    "config.noise_lambda = 1.0 # Lambda for exponential and Poisson distribution\n",
    "config.noise_alpha = 2.0  # Alpha for gamma distribution\n",
    "config.noise_beta = 1.0   # Beta for gamma distribution\n",
    "config.noise_type = 'gamma' #'lognormal' #'exponential' # 'uniform' #'normal'  # Default noise type\n",
    "\n",
    "\n",
    "# Check for GPU and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "# Define Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        # x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.tanh(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Define Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        self.fc4 = nn.Linear(hidden_size, input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        # x = self.relu(self.fc2(x))\n",
    "        # x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate models and move to device\n",
    "G = Generator(config.latent_size, config.hidden_size, config.image_size).to(device)\n",
    "D = Discriminator(config.image_size, config.hidden_size).to(device)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=config.learning_rate)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=config.learning_rate)\n",
    "\n",
    "\n",
    "# Monobit Frequency Test: Check if the number of 1's and 0's are approximately equal.\n",
    "def monobit_frequency_test(noise):\n",
    "    n = len(noise)\n",
    "    count_ones = np.sum(noise)\n",
    "    S = abs(count_ones - (n - count_ones))\n",
    "    p_value = stats.norm.cdf(S / np.sqrt(n))  # Normal distribution approximation\n",
    "    return p_value\n",
    "\n",
    "# Block Frequency Test: Check if blocks of the sequence have an equal number of 1's and 0's.\n",
    "def block_frequency_test(noise, block_size=128):\n",
    "    \"\"\"\n",
    "    Block Frequency Test: Check if blocks of the sequence have an equal number of 1's and 0's.\n",
    "\n",
    "    Parameters:\n",
    "        noise (torch.Tensor): Binary noise sequence.\n",
    "        block_size (int): Size of each block to test.\n",
    "\n",
    "    Returns:\n",
    "        p_value (float): p-value of the test.\n",
    "    \"\"\"\n",
    "    # Calculate the number of blocks\n",
    "    num_blocks = len(noise) // block_size\n",
    "    \n",
    "    # Calculate the sum of 1's in each block\n",
    "    block_sums = [np.sum(noise[i * block_size: (i + 1) * block_size]) for i in range(num_blocks)]\n",
    "    \n",
    "    # Convert block_sums to a NumPy array to allow element-wise operations\n",
    "    block_sums = np.array(block_sums)\n",
    "    \n",
    "    # Perform the chi-squared test\n",
    "    chi_squared = 4 * block_size * np.sum(((block_sums - block_size / 2) / block_size) ** 2)\n",
    "    \n",
    "    # Calculate the p-value from the chi-squared statistic\n",
    "    p_value = stats.chi2.sf(chi_squared, num_blocks)  # Survival function\n",
    "    \n",
    "    return p_value\n",
    "\n",
    "\n",
    "# Runs Test: Tests the randomness of a sequence by examining the number of runs.\n",
    "def runs_test(noise):\n",
    "    n = len(noise)\n",
    "    count_ones = np.sum(noise)\n",
    "    count_zeros = n - count_ones\n",
    "    runs = 1 + np.sum(noise[1:] != noise[:-1])\n",
    "    expected_runs = 2 * count_ones * count_zeros / n + 1\n",
    "    variance_runs = 2 * count_ones * count_zeros * (2 * count_ones * count_zeros - n) / (n ** 2 * (n - 1))\n",
    "    z = abs(runs - expected_runs) / np.sqrt(variance_runs)\n",
    "    p_value = 2 * stats.norm.cdf(-z)  # Two-tailed test\n",
    "    return p_value\n",
    "\n",
    "# Longest Runs of Ones in a Block Test\n",
    "def longest_runs_of_ones_test(noise, block_size=128):\n",
    "    num_blocks = len(noise) // block_size\n",
    "    longest_runs = [np.max(np.diff(np.where(np.concatenate(([0], noise[i * block_size:(i + 1) * block_size], [0])) == 0))) \n",
    "                    for i in range(num_blocks)]\n",
    "    p_value = stats.chi2.sf(np.sum(longest_runs), num_blocks)\n",
    "    return p_value\n",
    "\n",
    "# Add more tests as necessary...\n",
    "\n",
    "def noise_metrics(noise):\n",
    "    \"\"\"\n",
    "    Calculate and log metrics for the generated noise.\n",
    "    \n",
    "    Metrics calculated:\n",
    "        - Mean\n",
    "        - Standard Deviation\n",
    "        - Skewness\n",
    "        - Kurtosis\n",
    "        - Entropy\n",
    "        - Range\n",
    "        - Randomness Tests: Monobit Frequency, Block Frequency, Runs Test, Longest Runs of Ones\n",
    "    \n",
    "    Parameters:\n",
    "        noise (torch.Tensor): The noise tensor to analyze.\n",
    "    \"\"\"\n",
    "    noise_np = noise.cpu().numpy()\n",
    "\n",
    "    # Statistical metrics\n",
    "    mean = np.mean(noise_np)\n",
    "    std = np.std(noise_np)\n",
    "    skewness = np.mean((noise_np - mean) ** 3) / std**3\n",
    "    kurtosis = np.mean((noise_np - mean) ** 4) / std**4 - 3\n",
    "    noise_range = np.max(noise_np) - np.min(noise_np)\n",
    "    \n",
    "    hist, _ = np.histogram(noise_np, bins=100, density=True)\n",
    "    hist = hist[hist > 0]\n",
    "    entropy = -np.sum(hist * np.log(hist))\n",
    "\n",
    "    # Convert noise to binary for randomness tests (e.g., threshold at 0.5)\n",
    "    binary_noise = (noise_np > 0.5).astype(int)\n",
    "\n",
    "    # Randomness tests\n",
    "    p_monobit = monobit_frequency_test(binary_noise)\n",
    "    p_block = block_frequency_test(binary_noise)\n",
    "    p_runs = runs_test(binary_noise)\n",
    "    p_longest_runs = longest_runs_of_ones_test(binary_noise)\n",
    "\n",
    "    # Log metrics to Weights & Biases\n",
    "    wandb.log({\n",
    "        \"Noise Mean\": mean,\n",
    "        \"Noise Std\": std,\n",
    "        \"Noise Skewness\": skewness,\n",
    "        \"Noise Kurtosis\": kurtosis,\n",
    "        \"Noise Range\": noise_range,\n",
    "        \"Noise Entropy\": entropy,\n",
    "        \"Monobit Frequency Test\": p_monobit,\n",
    "        \"Block Frequency Test\": p_block,\n",
    "        \"Runs Test\": p_runs,\n",
    "        \"Longest Runs of Ones Test\": p_longest_runs\n",
    "    })\n",
    "\n",
    "\n",
    "def generate_noise(batch_size, latent_size, noise_type='normal'):\n",
    "    \"\"\"\n",
    "    Generates noise based on different distributions and logs metrics for the noise.\n",
    "\n",
    "    Parameters:\n",
    "        batch_size (int): The number of noise vectors to generate.\n",
    "        latent_size (int): The size of each noise vector.\n",
    "        noise_type (str): The type of distribution to sample from.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The generated noise vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    if noise_type == 'normal':\n",
    "        z = torch.randn(batch_size, latent_size).to(device) * config.noise_std + config.noise_mean\n",
    "\n",
    "    elif noise_type == 'uniform':\n",
    "        z = torch.rand(batch_size, latent_size).to(device) * (config.noise_max - config.noise_min) + config.noise_min\n",
    "\n",
    "    elif noise_type == 'exponential':\n",
    "        z = torch.distributions.Exponential(config.noise_lambda).sample((batch_size, latent_size)).to(device)\n",
    "\n",
    "    elif noise_type == 'lognormal':\n",
    "        z = torch.distributions.LogNormal(config.noise_mean, config.noise_std).sample((batch_size, latent_size)).to(device)\n",
    "\n",
    "    elif noise_type == 'gamma':\n",
    "        z = torch.distributions.Gamma(config.noise_alpha, config.noise_beta).sample((batch_size, latent_size)).to(device)\n",
    "\n",
    "    elif noise_type == 'poisson':\n",
    "        z = torch.poisson(torch.full((batch_size, latent_size), config.noise_lambda)).to(device)\n",
    "\n",
    "    elif noise_type == 'random_binary':\n",
    "        z = torch.randint(0, 2, (batch_size, latent_size)).float().to(device)  # Binary random noise\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported noise type: {noise_type}\")\n",
    "\n",
    "    # # Log noise distribution type and parameters\n",
    "    # wandb.log({\n",
    "    #     \"Noise Type\": noise_type,\n",
    "    #     \"Noise Mean\": config.noise_mean if noise_type in ['normal', 'lognormal'] else -100,\n",
    "    #     \"Noise Std\": config.noise_std if noise_type in ['normal', 'lognormal'] else -100,\n",
    "    #     \"Noise Lambda\": config.noise_lambda if noise_type in ['exponential', 'poisson'] else -100,\n",
    "    #     \"Noise Alpha\": config.noise_alpha if noise_type == 'gamma' else -100,\n",
    "    #     \"Noise Beta\": config.noise_beta if noise_type == 'gamma' else -100,\n",
    "    #     \"Noise Min\": config.noise_min if noise_type == 'uniform' else -100,\n",
    "    #     \"Noise Max\": config.noise_max if noise_type == 'uniform' else -100\n",
    "    # })\n",
    "\n",
    "    # Calculate and log noise metrics\n",
    "    # noise_metrics(z)\n",
    "\n",
    "    return z\n",
    "\n",
    "# Define the stopping criterion (number of consecutive epochs)\n",
    "stop_epochs_threshold = 5  # Stop after this many consecutive epochs where the condition is met\n",
    "\n",
    "# Initialize the counter for consecutive successful epochs\n",
    "consecutive_epochs = 0\n",
    "\n",
    "\n",
    "# Training loop\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        images = images.reshape(config.batch_size, -1).to(device)\n",
    "        real_labels = torch.ones(config.batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(config.batch_size, 1).to(device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "\n",
    "        # Generate noise with tunable parameters\n",
    "        z = generate_noise(config.batch_size, config.latent_size, config.noise_type)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Train Generator\n",
    "        z = generate_noise(config.batch_size, config.latent_size, config.noise_type)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # Print and log progress\n",
    "        if (i + 1) % (len(data_loader) // 4) == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f'Epoch [{epoch}/{config.num_epochs}], Step [{i + 1}/{len(data_loader)}], '\n",
    "                  f'D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}, '\n",
    "                  f'D(x): {real_score.mean().item():.2f}, D(G(z)): {fake_score.mean().item():.2f}, '\n",
    "                  f'Time Elapsed: {elapsed_time:.2f} sec')\n",
    "\n",
    "            noise_metrics(z)\n",
    "\n",
    "\n",
    "            # Log metrics to W&B\n",
    "            wandb.log({\n",
    "                'Epoch': epoch,\n",
    "                'D Loss': d_loss.item(),\n",
    "                'G Loss': g_loss.item(),\n",
    "                'D(x)': real_score.mean().item(),\n",
    "                'D(G(z))': fake_score.mean().item(),\n",
    "                'Time Elapsed': elapsed_time\n",
    "            })\n",
    "    \n",
    "    # Stopping criterion\n",
    "    if real_score.mean().item() >= 0.98 and fake_score.mean().item() <= 0.02:\n",
    "        consecutive_epochs += 1\n",
    "    else:\n",
    "        consecutive_epochs = 0\n",
    "\n",
    "    # Check if the stopping criterion is met\n",
    "    if consecutive_epochs >= stop_epochs_threshold:\n",
    "        print(f\"Stopping training as D(x) ≈ 1.00 and D(G(z)) ≈ 0.00 for {stop_epochs_threshold} consecutive epochs.\")\n",
    "        break\n",
    "\n",
    "    # Save and visualize generated images\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
    "            grid = torchvision.utils.make_grid(fake_images, nrow=10, normalize=True)\n",
    "            plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "            plt.show()\n",
    "\n",
    "# Save models\n",
    "timestamp = dt.datetime.now().strftime(\"%y%m%d%H%M%S\")\n",
    "torch.save(G.state_dict(), f'models/generator_{timestamp}.pth')\n",
    "torch.save(D.state_dict(), f'models/discriminator_{timestamp}.pth')\n",
    "\n",
    "# End W&B run\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qfcmolgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
